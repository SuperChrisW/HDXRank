{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchdrug import data\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/lwang/AI-HDX-main/ProteinComplex_HDX_prediction/BiLSTM+GAT_v2/pepGraph_generation\")\n",
    "from GearNet import GearNet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device, rm_feat):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for graph_batch in test_loader: \n",
    "            graph_batch = graph_batch.to(device)\n",
    "            targets = graph_batch.y\n",
    "            if rm_feat == 'msa':\n",
    "                node_feat = graph_batch.residue_feature[:,30:].float()\n",
    "            elif rm_feat == 'sequence':\n",
    "                node_feat = torch.cat([graph_batch.residue_feature[:,:30].float(), graph_batch.residue_feature[:,40:].float()], dim=1) # remove seq feat\n",
    "            elif rm_feat == 'physical':\n",
    "                node_feat = torch.cat([graph_batch.residue_feature[:,:40].float(), graph_batch.residue_feature[:,44:].float()], dim=1) # remove physical feat\n",
    "            elif rm_feat == 'geometric':\n",
    "                node_feat = torch.cat([graph_batch.residue_feature[:,:44].float(), graph_batch.residue_feature[:,56:].float()], dim=1) # remove geometric feat\n",
    "            elif rm_feat == 'heteroatom':\n",
    "                node_feat = graph_batch.residue_feature[:,:56].float() # remove heteroatom feat\n",
    "            elif rm_feat == 'none':\n",
    "                node_feat = graph_batch.residue_feature.float()\n",
    "            #node_feat = torch.cat([graph_batch.residue_feature[:,:35].float(), graph_batch.residue_feature[:,40:41].float()], dim=1) # same as AI-HDX\n",
    "            outputs = model(graph_batch, node_feat)\n",
    "\n",
    "            y_pred.extend(outputs.cpu().detach().numpy())\n",
    "            y_true.extend(targets.cpu().detach().numpy())\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def plot_results(y_true, y_pred):\n",
    "    plt.scatter(y_true, y_pred, s=1)\n",
    "    plt.plot([0, 1], [0, 1], color=\"red\", linestyle=\"--\")\n",
    "    pcc = pearsonr(y_true, y_pred)[0]\n",
    "    spR = spearmanr(y_true, y_pred)[0]\n",
    "    plt.legend([\"PCC: %.3f\" % pcc, \"SPR: %.3f\" % spR], loc=\"upper left\")\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'num_epochs':150,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 5e-4,\n",
    "        'GNN_type': 'GAT',\n",
    "        'num_GNN_layers': 3,\n",
    "        'cross_validation_num': 1,\n",
    "        'num_workers': 4,\n",
    "}\n",
    "\n",
    "training_args = {'num_hidden_channels': 10, 'num_out_channels': 20, \n",
    "\n",
    "        'feat_in_dim': 56, 'topo_in_dim': 42, 'num_heads': 8, 'GNN_hidden_dim': 32,\n",
    "        'GNN_out_dim': 64, 'LSTM_out_dim': 64,\n",
    "\n",
    "        'final_hidden_dim': 16,\n",
    "\n",
    "        'drop_out': 0.5, 'num_GNN_layers': config['num_GNN_layers'], 'GNN_type': config['GNN_type'],\n",
    "        'graph_hop': 'hop1', 'batch_size': config['batch_size'],\n",
    "        'result_dir': '/home/lwang/models/HDX_LSTM/results/240601_finalExp',\n",
    "        'data_log': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### initial setting ##################################### \n",
    "root_dir = '/home/lwang/models/HDX_LSTM/data/Latest_test'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cluster = 'cluster1_8A_manual_rescale'\n",
    "rm_feat = 'none'\n",
    "model_name = 'GearNet'\n",
    "model_fpath = f'/home/lwang/models/HDX_LSTM/results/241110_GearNet/model_GN56_{cluster}_v0_{rm_feat}_epoch99.pth'\n",
    "pepGraph_dir = os.path.join(root_dir, 'graph_ensemble_simpleGearNet', cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of graphs: 1250\n"
     ]
    }
   ],
   "source": [
    "##################################### data loading ##################################### \n",
    "input_graph = []\n",
    "for file in os.listdir(pepGraph_dir):\n",
    "    pepGraph_file = f'{pepGraph_dir}/{file}'\n",
    "    pepGraph_ensemble = torch.load(pepGraph_file)\n",
    "    input_graph.extend(pepGraph_ensemble)\n",
    "print(f\"Total number of graphs: {len(input_graph)}\")\n",
    "\n",
    "#GearNet\n",
    "feat_num = {\"sequence\": 10, \"msa\": 30, \"physical\": 4, \"geometric\": 12, \"heteroatom\": 42, 'none': 0, '36feat': 62}\n",
    "model = GearNet(input_dim = 56-feat_num[rm_feat], hidden_dims = [512,512,512],\n",
    "                num_relation=7, batch_norm=True, concat_hidden=True, readout='sum', activation = 'relu', short_cut=True)\n",
    "\n",
    "model_state_dict = torch.load(model_fpath, map_location=device)\n",
    "model_state_dict = model_state_dict['model_state_dict'] # add if saved as checkpoint\n",
    "model.load_state_dict(model_state_dict)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_set = data.Protein.pack(input_graph)\n",
    "total_dataloader = data.DataLoader(total_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_true, y_pred, range_list, chain_list \u001b[38;5;241m=\u001b[39m test_model(model, total_dataloader, device, rm_feat)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_true\u001b[38;5;241m.\u001b[39mshape, y_pred\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m pcc \u001b[38;5;241m=\u001b[39m pearsonr(y_true, y_pred)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = test_model(model, total_dataloader, device, rm_feat)\n",
    "print(y_true.shape, y_pred.shape)\n",
    "rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "pcc = pearsonr(y_true, y_pred)[0]\n",
    "spR = spearmanr(y_true, y_pred)[0]\n",
    "print(f'PCC: {pcc}, SPR: {spR}, RMSE: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
