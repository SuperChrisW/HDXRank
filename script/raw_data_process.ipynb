{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 19, 21, 29, 29, 32, 32, 37, 32, 56, 59, 64, 66, 66, 69, 81, 81, 98, 98, 100, 101, 100, 102, 101, 102, 112, 113, 122, 125, 126, 127, 139, 143, 144, 156, 162, 163, 165, 164, 165, 166, 171, 182, 182, 190, 190, 198, 29, 38, 60, 55, 55, 82, 87, 89, 89, 90, 92, 92, 89, 92, 109, 111, 121, 121, 123, 124, 123, 125, 126, 136, 145, 148, 149, 150, 150, 166, 167, 170, 179, 185, 187, 194, 198, 199, 213, 213, 221, 30, 30, 30, 51, 51, 51, 83, 84, 85, 85, 88, 100, 110, 110, 117, 119, 131, 141, 145, 146, 162, 163, 162, 181, 181, 190, 205, 209, 210, 28, 26, 28, 26, 28, 39, 39, 44, 44, 46, 46, 64, 65, 72, 75, 72, 75, 72, 92, 97, 97, 97, 108, 108, 119, 132, 145, 149, 150, 170, 177, 177, 188, 189, 188, 188, 189, 192, 198, 196, 204, 30, 38, 51, 51, 51, 56, 71, 78, 84, 86, 89, 89, 101, 104, 106, 118, 118, 142, 164, 163, 176, 176, 191, 191, 210, 218]\n",
      "[13, 15, 20, 28, 31, 36, 55, 52, 53, 48, 55, 60, 65, 80, 80, 81, 80, 86, 100, 110, 112, 110, 110, 112, 110, 112, 112, 121, 121, 138, 138, 138, 138, 143, 155, 155, 164, 181, 181, 179, 181, 181, 181, 181, 189, 191, 197, 202, 202, 39, 54, 71, 77, 78, 88, 103, 103, 104, 103, 103, 104, 108, 108, 120, 120, 133, 135, 133, 132, 135, 135, 137, 144, 161, 161, 161, 161, 163, 178, 178, 178, 193, 193, 192, 204, 204, 204, 220, 225, 225, 37, 39, 50, 71, 73, 74, 99, 99, 99, 100, 99, 109, 129, 131, 129, 129, 140, 157, 157, 157, 174, 174, 183, 189, 200, 200, 210, 221, 221, 35, 38, 38, 43, 45, 54, 58, 54, 58, 58, 60, 71, 71, 86, 86, 91, 91, 96, 96, 105, 106, 118, 117, 118, 127, 144, 149, 161, 161, 176, 187, 195, 195, 195, 197, 203, 203, 203, 203, 208, 208, 37, 50, 55, 73, 74, 73, 76, 85, 100, 100, 100, 101, 105, 110, 117, 130, 132, 158, 172, 174, 184, 190, 201, 205, 222, 222]\n",
      "MEGKWSKRSVSGWRMRRAEPAAEGVGAVSRDLEKHGAITSSNTAWLEAEEVGFPVRPQVPLRPMTYKAAVDEGLIYSQKRQDILLWVYHTQGYFPDWQNYTPGPGIRYPLTFGWCFKLVPVEPEKVEEANEGENNCLLHPMSQHGMDDPEKEVWKFDSKLAFHHMARELHPEYAFHHMARE\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/dataset/'\n",
    "path = f'{root_dir}/MASSIVE-COMPLETE-9dffe2a9-display_quant_results-main.tsv'\n",
    "path = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/dataset/percentage/HIV-1_nef.csv'\n",
    "df = pd.read_csv(path)\n",
    "index_list = df.index.tolist()\n",
    "#start_name_list = df[\"Start\"].tolist()\n",
    "#end_name_list = df[\"End\"].tolist()\n",
    "sequence_list = df[\"Sequence\"].tolist()\n",
    "range_list = df[\"Range\"].tolist()\n",
    "start_name_list = []\n",
    "end_name_list = []\n",
    "for item in range_list:\n",
    "    start_name_list.append(int(item.split('‐')[0]))\n",
    "    end_name_list.append(int(item.split('‐')[1]))\n",
    "\n",
    "print(start_name_list)\n",
    "print(end_name_list)\n",
    "def protein_merge(start, end, sequence):\n",
    "    \n",
    "    def protein_finder(merged_protein, start, end, sequence, position): #recursive function\n",
    "        if end[position] > start[len(start)-1]: #this deals with the end of the sequence\n",
    "            return merged_protein\n",
    "\n",
    "        for i in range(position, len(start)):\n",
    "            if start[i] - end[position] > 0 and start[i] - end[position] <= 100:\n",
    "                merged_protein += sequence[i]\n",
    "                return protein_finder(merged_protein, start, end, sequence, i)\n",
    "        \n",
    "        return merged_protein\n",
    "    \n",
    "    position = 0 #position is the current position of the list\n",
    "    for i in range(len(start)): #it iterates down the start list, and breaks the for loop once a positive start value is reached\n",
    "        if start[i] > 0:\n",
    "            position = i\n",
    "            break\n",
    "        \n",
    "    merged_protein = sequence[position]#then it takes the first protein at the position\n",
    "    x = protein_finder(merged_protein, start, end, sequence, position) \n",
    "    return x\n",
    "\n",
    "e = protein_merge(start_name_list, end_name_list, sequence_list)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "PXD045520\n",
      "['D380A_OLF_state_data.csv', 'I499F_OLF_state_data.csv', 'WT_OLF_state_data.csv']\n"
     ]
    }
   ],
   "source": [
    "#count = 59\n",
    "print(count)\n",
    "data_file = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/merge_sequence.xlsx'\n",
    "data_df = pd.read_excel(data_file, sheet_name='merge_sequence')\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "folder_list = list(data_df['Dataset_Identifier'].unique())\n",
    "\n",
    "print(folder_list[count])\n",
    "\n",
    "try:\n",
    "    folder_name = folder_list[count].replace(' ', '')\n",
    "    file_list = os.listdir(f'{root_dir}/{folder_name}')\n",
    "\n",
    "    if '.DS_Store' in file_list:\n",
    "        file_list.remove('.DS_Store')\n",
    "    print(file_list)\n",
    "\n",
    "    count += 1\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D380A_OLF_state_data.csv\n",
      "['Default State']\n",
      "(810, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for index, file in enumerate(file_list):\n",
    "\n",
    "sheet_name_set = 'HDX Data Table (Table S4)'\n",
    "file = file_list[0]\n",
    "path = f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/{folder_name}/{file}'\n",
    "if file.split('.')[-1] == 'csv':\n",
    "    df = pd.read_csv(path)\n",
    "elif file.split('.')[-1] == 'xlsx':\n",
    "    df = pd.read_excel(path, sheet_name=sheet_name_set)\n",
    "\n",
    "### screening for the state\n",
    "#    mono_state = file.split('_')[0]\n",
    "#    df.loc[df['State'] == 'CSN', 'State'] = mono_state\n",
    "#    df.loc[df['State'].str.contains('-') & df['State'].str.contains('CSN'), 'State'] = mono_state+'-CRL2'\n",
    "#    df.to_csv(path, index=False)\n",
    "### end ###\n",
    "\n",
    "state_values = list(df['State'].unique())\n",
    "print(file)\n",
    "print(state_values)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606, 23)\n",
      "(606, 23)\n"
     ]
    }
   ],
   "source": [
    "##manually set apo states\n",
    "apo_state = ['apo'] \n",
    "\n",
    "folder = folder_name\n",
    "if os.path.exists(f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/{folder}/apo.xlsx'):\n",
    "    apo_df = pd.read_excel(f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/{folder}/apo.xlsx')\n",
    "    mutation_df = pd.read_excel(f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/{folder}/mutation.xlsx')\n",
    "    pass\n",
    "else:\n",
    "    apo_df = pd.DataFrame()\n",
    "    mutation_df = pd.DataFrame()\n",
    "\n",
    "#for index, file in enumerate(file_list):\n",
    "\n",
    "path = f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/{folder_name}/{file}'\n",
    "if file.split('.')[-1] == 'csv':\n",
    "    df = pd.read_csv(path)\n",
    "elif file.split('.')[-1] == 'xlsx':\n",
    "    df = pd.read_excel(path, sheet_name=sheet_name_set)\n",
    "\n",
    "apo_mask = df['State'].isin(apo_state)\n",
    "apo_add = df[apo_mask].copy()\n",
    "mutation_add = df[~apo_mask].copy()\n",
    "#apo_add['Protein'] = 'GoA-beta'\n",
    "#mutation_add['Protein'] = 'GoA-beta'\n",
    "\n",
    "apo_df = pd.concat([apo_df,apo_add])\n",
    "mutation_df = pd.concat([mutation_df, mutation_add])\n",
    "\n",
    "print(apo_df.shape)\n",
    "print(mutation_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = folder_name\n",
    "apo_df.to_excel(f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/{folder}/apo.xlsx', index=False)\n",
    "mutation_df.to_excel(f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/{folder}/mutation.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FNKTKSVE', 'FVTNMEAQNTTEVYVKWKFKGRDIYT', 'TTEVYVKWKFKGRD', 'TEVYVKWKFKGRDI', 'EVYVKWKFKGRDIY', 'YVKWKFKGRD', 'SSAKIEVSQL', 'AKIEVSQL', 'KIEVSQL', 'SQLLKGDASLKMDKSD', 'LTREGETIIE', 'TREGETIIE', 'LKYRVVSWFSPNENIL', 'KYRVVSWFSPNENIL', 'RVVSWFSPNENIL', 'FSPNENIL', 'KYRVVSWFSPNENILIVIFPIFAILLFW', 'LLFWGQFGIKTLKYRSGAD', 'FWGQFGIKTLKYRSGAD', 'WGQFGIKTLKYRSGAD', 'GIKTLKYRSGADL', 'EDNWETL', 'EDNWETLNDNL', 'NWETLNDNL', 'WETLNDNL', 'ETLNDNL', 'ETLNDNLKVIEKADNAAQVKDALTKMRA', 'NLKVIEKADNAAQVKDAL', 'KVIEKADNAAQVKDAL', 'IEKADNAAQVKDAL', 'NLKVIEKADNAAQVKDALTKMRA', 'KVIEKADNAAQVKDALTKM', 'KADNAAQVKDAL', 'KVIEKADNAAQVKDALTKMRA', 'KVIEKADNAAQVKDALTKMRAAAL', 'QVKDAL', 'AAQVKDALTKMR', 'AAQVKDALTKMRA', 'TKMRAAAL', 'DAQKATPPKLED', 'LDAQKATPPKLEDKSPDSPE', 'DAQKATPPKLEDKSPDSPEM', 'DAQKATPPKLEDKSPDSPEMKD', 'DAQKATPPKLEDKSPDSPEMKDFRHGF', 'LEDKSPDSP', 'DAQKATPPKLEDKSPDSPEMKDFRHGFD', 'DAQKATPPKLEDKSPDSPEMKDFRHGFDIL', 'EDKSPDSPEMKD', 'EDKSPDSPEMKDFRHGFDIL', 'KDFRHGFDIL', 'FRHGFDIL', 'VGQIDDAL', 'VGQIDDALKLANEGKVKEAQA', 'VGQIDDALKLANEGKVKEAQAAAEQL', 'LKLANEGKVKEAQAAA', 'LKLANEGKVKEAQAAAE', 'LKLANEGKVKEAQAAAEQL', 'LANEGKVKEAQAAAEQLK', 'AAAEQLKTTRNAYIQKYL', 'YSLKNATGLGL', 'IVTSTGIL', 'ILLHYYVFSTAIGLT', 'ACIPMHGPLL', 'KFVASNQKT', 'VYMKFVASNQKTIQPPR', 'SNQKTIQPPR', 'KFVASNQKTIQPPRKAVEEPLNA', 'VASNQKTIQPPRKAVEEPLNA', 'KTIQPPRKAVEEPLNA', 'FKESKGMM']\n",
      "(280, 6)\n"
     ]
    }
   ],
   "source": [
    "### for columns contains multiple time HDX\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "folder = 'PXD026458'\n",
    "file = 'CD47_HDX_Table_2.xlsx'\n",
    "sheet_name_set = 'Sheet2'\n",
    "seq_col = [0,1,2]\n",
    "uptake_col = ['AY', 'BA', 'BC', 'BE']\n",
    "#uptake_col = ['E', 'G', 'I', 'K']\n",
    "start_row = 2\n",
    "\n",
    "def column_letter_to_index(column_letter):\n",
    "    column_number = 0\n",
    "    for letter in column_letter:\n",
    "        column_number = column_number * 26 + (ord(letter.upper()) - ord('A')) + 1\n",
    "    return column_number - 1\n",
    "\n",
    "def data_rearrange(df, seq_col, uptake_col, col_names):\n",
    "    rearrg_data = pd.DataFrame()\n",
    "    for col in uptake_col:\n",
    "        col = column_letter_to_index(col)\n",
    "        assemble_col = seq_col + [col]\n",
    "        new_df = df.iloc[:, assemble_col]\n",
    "        new_df.columns = col_names\n",
    "\n",
    "        rearrg_data = pd.concat([rearrg_data, new_df], axis = 0, ignore_index=True)\n",
    "    #rearrg_data['protein'] = ''\n",
    "    rearrg_data['exposure'] = ''\n",
    "    rearrg_data['state'] = 'CD47-F119A'\n",
    "    return rearrg_data\n",
    "\n",
    "path = f'{root_dir}/{folder}/{file}'\n",
    "rearrg_df = pd.read_excel(path, sheet_name=sheet_name_set)\n",
    "rearrg_df = rearrg_df.iloc[start_row:]\n",
    "\n",
    "column_0_unique_values = rearrg_df.iloc[:, 0].unique().tolist()\n",
    "column_0_unique_values = [x for x in column_0_unique_values if str(x) != 'nan']\n",
    "print(column_0_unique_values)\n",
    "\n",
    "df_list = []\n",
    "col_names = ['sequence', 'start', 'end', 'uptake']\n",
    "for value in column_0_unique_values:\n",
    "    df = rearrg_df[rearrg_df.iloc[:, 0] == value]\n",
    "    output = data_rearrange(rearrg_df, seq_col, uptake_col, col_names)\n",
    "    print(output.shape)\n",
    "    df_list.append(output)\n",
    "    break\n",
    "\n",
    "final_df = pd.concat(df_list, axis = 0, ignore_index=True)\n",
    "\n",
    "file = 'mutation'\n",
    "if os.path.exists(f'{root_dir}/{folder}/{file}.xlsx'):\n",
    "    ori_df = pd.read_excel(f'{root_dir}/{folder}/{file}.xlsx')\n",
    "    final_df = pd.concat([ori_df, final_df], axis = 0)\n",
    "final_df.to_excel(f'{root_dir}/{folder}/{file}.xlsx', index=False)\n",
    "#df_list[1].to_excel(f'{root_dir}/{folder}/mutation.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 6)\n",
      "(600, 6)\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_excel(f'{root_dir}/{folder}/mutation.xlsx')\n",
    "print(new_df.shape)\n",
    "\n",
    "new_df = new_df[~new_df['start'].astype(str).str.contains('BRIL')]\n",
    "new_df = new_df.dropna(subset=['uptake'])\n",
    "\n",
    "print(new_df.shape)\n",
    "new_df.to_excel(f'{root_dir}/{folder}/mutation_revised.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apo/mutation data merge ###\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "folder = os.listdir(root_dir)\n",
    "\n",
    "def clean_format(path):\n",
    "    df = pd.read_excel(path)\n",
    "    df.columns = df.columns.str.upper()\n",
    "\n",
    "    if 'PROTEIN' not in df.columns:\n",
    "        df['PROTEIN'] = 'nan'\n",
    "\n",
    "    col_name = [col for col in df.columns if 'UPTAKE' in col or '#D' in col]\n",
    "    if col_name:\n",
    "        col_name = col_name[0]\n",
    "    elif '%D' in df.columns:\n",
    "        col_name = '%D'\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    df = df.dropna(subset=[col_name, 'SEQUENCE'])\n",
    "\n",
    "    if 'EXPOSRUE' not in df.columns:\n",
    "        subset = ['STATE', 'SEQUENCE']\n",
    "    else:\n",
    "        subset = ['STATE', 'SEQUENCE', 'EXPOSURE']\n",
    "    df.drop_duplicates(subset=subset, inplace=True)\n",
    "    return df\n",
    "\n",
    "apo_df = pd.DataFrame()\n",
    "mutation_df = pd.DataFrame()\n",
    "temp_df = pd.DataFrame()\n",
    "for folder_name in folder:\n",
    "    print(folder_name)\n",
    "    if os.path.exists(f'{root_dir}/{folder_name}/mutation.xlsx'):\n",
    "        path = f'{root_dir}/{folder_name}/mutation.xlsx'\n",
    "        temp_df = clean_format(path)\n",
    "        print('mutation + ', temp_df.shape[0])\n",
    "        mutation_df = pd.concat([mutation_df, temp_df])\n",
    "    if os.path.exists(f'{root_dir}/{folder_name}/apo.xlsx'):\n",
    "        path = f'{root_dir}/{folder_name}/apo.xlsx'\n",
    "        temp_df = clean_format(path)\n",
    "        print('apo + ', temp_df.shape[0])\n",
    "        apo_df = pd.concat([apo_df, temp_df])\n",
    "\n",
    "print('apo_shape:', apo_df.shape) \n",
    "print('mutation_shape:', mutation_df.shape)\n",
    "\n",
    "apo_df.to_excel(f'{root_dir}/apo.xlsx', index=False)\n",
    "mutation_df.to_excel(f'{root_dir}/mutation.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardize format of apo and mutation files ###\n",
    "\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "raw_df = pd.read_excel(f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/merge_sequence.xlsx')\n",
    "folder = raw_df['Dataset_Identifier'].unique().tolist()\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def clean_format(path, protein, database_id):\n",
    "    df = pd.read_excel(path)\n",
    "    df.columns = df.columns.map(str)\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    if 'protein' not in df.columns:\n",
    "        df['protein'] = protein\n",
    "    if 'database_id' not in df.columns:\n",
    "        df['database_id'] = database_id\n",
    "\n",
    "    #if 'exposure' in df.columns:\n",
    "    #    df = df[df['exposure'].apply(lambda x: is_number(x) and float(x) != 0)]\n",
    "    df = df[df['exposure'] != '0s']\n",
    "\n",
    "    temp_col = ''\n",
    "    if 'uptake' in df.columns:\n",
    "        df = df.dropna(subset=['uptake', 'sequence'])\n",
    "    elif '%d' in df.columns:\n",
    "        temp_col = '%d'\n",
    "        df = df.dropna(subset=['%d', 'sequence'])\n",
    "    elif 'd%' in df.columns:\n",
    "        temp_col = 'd%'\n",
    "        df = df.dropna(subset=['d%', 'sequence'])\n",
    "    #df = df.dropna(subset=['exposure'])\n",
    "\n",
    "    subset = ['state', 'sequence', 'exposure']\n",
    "\n",
    "    temp_size = df.shape[0]\n",
    "    modified_df = df.drop_duplicates(subset=subset)\n",
    "    if modified_df.shape[0] != temp_size:\n",
    "        print('duplicates found at ', database_id)\n",
    "        pass\n",
    "\n",
    "    col_keep = ['database_id', 'protein', 'state','start', 'end', 'sequence', 'exposure', 'uptake', temp_col]\n",
    "    df = df[df.columns.intersection(col_keep)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates found at  PXD013001\n",
      "duplicates found at  PXD013001\n",
      "duplicates found at  PXD013001\n",
      "duplicates found at  PXD013001\n",
      "duplicates found at  PXD017095\n",
      "duplicates found at  PXD018172\n",
      "duplicates found at  PXD018921\n",
      "duplicates found at  PXD019199\n",
      "duplicates found at  PXD019199\n",
      "duplicates found at  PXD019530\n",
      "duplicates found at  PXD019810\n",
      "duplicates found at  PXD019810\n",
      "duplicates found at  PXD019884\n",
      "duplicates found at  PXD019884\n",
      "duplicates found at  PXD020890\n",
      "duplicates found at  PXD041359\n",
      "'float' object has no attribute 'strip'\n"
     ]
    }
   ],
   "source": [
    "### generate apo_revised.xlsx and mutation_revised.xlsx ###\n",
    "### collect specific columns, remove exposure == 0, remove empty records ###\n",
    "\n",
    "for folder_name in folder:\n",
    "    try:\n",
    "        protein = ''\n",
    "        folder_name = folder_name.strip()\n",
    "        database_id = folder_name\n",
    "        \n",
    "        #print(folder_name)   \n",
    "        if os.path.isfile(f'{root_dir}/{folder_name}/mutation.xlsx'):\n",
    "            path = f'{root_dir}/{folder_name}/mutation.xlsx'\n",
    "            mutation_df = clean_format(path, protein, database_id)\n",
    "            #print('mutation + ', mutation_df.shape[0])\n",
    "            mutation_df.to_excel(f'{root_dir}/{folder_name}/mutation_revised.xlsx', index=False)\n",
    "\n",
    "        if os.path.isfile(f'{root_dir}/{folder_name}/apo.xlsx'):\n",
    "            path = f'{root_dir}/{folder_name}/apo.xlsx'\n",
    "            apo_df = clean_format(path, protein, database_id)\n",
    "            #print('apo + ', apo_df.shape[0])\n",
    "            apo_df.to_excel(f'{root_dir}/{folder_name}/apo_revised.xlsx', index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mutation +  598\n",
      "apo +  299\n"
     ]
    }
   ],
   "source": [
    "### generate apo_revised.xlsx and mutation_revised.xlsx ###\n",
    "### deal with single file ###\n",
    "\n",
    "protein = ''\n",
    "folder_name = 'JACS_ADA'\n",
    "database_id = folder_name\n",
    "\n",
    "if os.path.exists(f'{root_dir}/{folder_name}/mutation.xlsx'):\n",
    "    path = f'{root_dir}/{folder_name}/mutation.xlsx'\n",
    "    mutation_df = clean_format(path, protein, database_id)\n",
    "    print('mutation + ', mutation_df.shape[0])\n",
    "    mutation_df.to_excel(f'{root_dir}/{folder_name}/mutation_revised.xlsx', index=False)\n",
    "\n",
    "if os.path.exists(f'{root_dir}/{folder_name}/apo.xlsx'):\n",
    "    path = f'{root_dir}/{folder_name}/apo.xlsx'\n",
    "    apo_df = clean_format(path, protein, database_id)\n",
    "    print('apo + ', apo_df.shape[0])\n",
    "    apo_df.to_excel(f'{root_dir}/{folder_name}/apo_revised.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.167, 1.0, 10.0}\n",
      "{0.167, 1.0, 4.01, 10.0, 25.110001, 251.110016}\n"
     ]
    }
   ],
   "source": [
    "### check exposure unit ###\n",
    "import pandas as pd\n",
    "import os\n",
    "folder = 'PXD041359'\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "\n",
    "if os.path.exists(f'{root_dir}/{folder}/apo_revised.xlsx'):\n",
    "    apo_df = pd.read_excel(f'{root_dir}/{folder}/apo_revised.xlsx')\n",
    "    if not apo_df.shape[0] == 0: \n",
    "        apo_df.columns = apo_df.columns.map(str).str.lower()\n",
    "        exposure = apo_df['exposure'].tolist()\n",
    "        exposrue = set(exposure)\n",
    "        print(exposrue)\n",
    "else:\n",
    "    print('no file')\n",
    "if os.path.exists(f'{root_dir}/{folder}/mutation_revised.xlsx'):\n",
    "    mut_df = pd.read_excel(f'{root_dir}/{folder}/mutation_revised.xlsx')\n",
    "    if not mut_df.shape[0] == 0:\n",
    "        mut_df.columns = mut_df.columns.map(str).str.lower()\n",
    "        exposure = mut_df['exposure'].tolist()\n",
    "        exposrue = set(exposure)\n",
    "        print(exposrue)\n",
    "else:\n",
    "    print('no file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 8)\n",
      "(598, 8)\n",
      "Empty DataFrame\n",
      "Columns: [database_id, protein, state, start, end, sequence, exposure, uptake]\n",
      "Index: []\n",
      "(299, 8)\n",
      "(598, 8)\n"
     ]
    }
   ],
   "source": [
    "print(apo_df.shape)\n",
    "print(mut_df.shape)\n",
    "\n",
    "duplicate_check = ['state', 'start', 'end', 'sequence', 'exposure']\n",
    "#dup_mask = apo_df.duplicated(subset=duplicate_check, keep=False)\n",
    "#print(apo_df[dup_mask])\n",
    "\n",
    "dup_mask = mut_df.duplicated(subset=duplicate_check, keep=False)\n",
    "print(mut_df[dup_mask])\n",
    "\n",
    "apo_df = apo_df.drop_duplicates(subset=duplicate_check)\n",
    "mut_df = mut_df.drop_duplicates(subset=duplicate_check)\n",
    "print(apo_df.shape)\n",
    "print(mut_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28170\n",
      "68972\n"
     ]
    }
   ],
   "source": [
    "## eliminate duplicate and calculate mean value ###\n",
    "\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "folder = os.listdir(root_dir)\n",
    "subset = ['state', 'sequence', 'exposure', 'start', 'end', 'uptake', '%d' , 'dataset_identifier']\n",
    "duplicate_check = ['state', 'sequence', 'exposure']\n",
    "apo_size = 0\n",
    "mut_size = 0\n",
    "\n",
    "def calculate_mean(df):\n",
    "    if '%d' in df.columns:\n",
    "        uptake_col = '%d'\n",
    "    elif 'd%' in df.columns:\n",
    "        uptake_col = 'd%'\n",
    "    else:\n",
    "        uptake_col = 'uptake'\n",
    "    result_df = df.groupby(duplicate_check, as_index=False).agg({uptake_col: 'mean'})\n",
    "    return result_df\n",
    "\n",
    "manager = open('/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection/manager.txt', 'r')\n",
    "manager.readline() #skip the first line\n",
    "for line in manager:\n",
    "    folder_name = line.strip().split(':')[0]\n",
    "    #print(folder_name)\n",
    "\n",
    "    if os.path.exists(f'{root_dir}/{folder_name}/apo_revised.xlsx'):\n",
    "        apo_df = pd.read_excel(f'{root_dir}/{folder_name}/apo_revised.xlsx')\n",
    "        if not apo_df.shape[0] == 0: \n",
    "            temp_size = apo_df.shape[0]\n",
    "\n",
    "            cols = apo_df.columns.intersection(subset)\n",
    "            apo_df = apo_df.dropna(subset=cols)\n",
    "            apo_df = apo_df.drop_duplicates(subset=duplicate_check)\n",
    "            apo_size += apo_df.shape[0]\n",
    "\n",
    "            if not temp_size == apo_df.shape[0]:\n",
    "                print('apo', folder_name)\n",
    "                print(temp_size, apo_df.shape[0])\n",
    "                apo_df = calculate_mean(apo_df)\n",
    "                apo_df.to_excel(f'{root_dir}/{folder_name}/apo_revised.xlsx', index=False)\n",
    "\n",
    "    if os.path.exists(f'{root_dir}/{folder_name}/mutation_revised.xlsx'):\n",
    "        mut_df = pd.read_excel(f'{root_dir}/{folder_name}/mutation_revised.xlsx')\n",
    "        if not mut_df.shape[0] == 0:\n",
    "            temp_size = mut_df.shape[0]\n",
    "\n",
    "            cols = mut_df.columns.intersection(subset)\n",
    "            mut_df = mut_df.dropna(subset=cols)\n",
    "            mut_df = mut_df.drop_duplicates(subset=duplicate_check)\n",
    "            mut_size += mut_df.shape[0]\n",
    "\n",
    "            if not temp_size == mut_df.shape[0]:\n",
    "                print('mutation', folder_name)\n",
    "                print(temp_size, mut_df.shape[0])\n",
    "                mut_df = calculate_mean(mut_df)\n",
    "                mut_df.to_excel(f'{root_dir}/{folder_name}/mutation_revised.xlsx', index=False)\n",
    "\n",
    "print(apo_size)\n",
    "print(mut_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "\n",
    "def modify(apo_df, time_scale):\n",
    "    # Convert the entire column once\n",
    "    if 'uptake' in apo_df.columns:\n",
    "        check = True\n",
    "        apo_df['uptake'] = apo_df['uptake'].astype(float)\n",
    "    apo_df['sequence'] = apo_df['sequence'].astype(str).str.upper()\n",
    "    apo_df['exposure'] = apo_df['exposure'].astype(str)\n",
    "    log_t = []\n",
    "    max_uptake = []\n",
    "    percentage_d = []\n",
    "\n",
    "    for index, row in apo_df.iterrows():\n",
    "        exposure = row['exposure']\n",
    "\n",
    "        if time_scale == 'sec':\n",
    "            if 's' in exposure:\n",
    "                exposure = exposure.split('s')[0]\n",
    "            log_t_value = np.log10(float(exposure))\n",
    "        elif time_scale == 'min':\n",
    "            if 'min' in exposure:\n",
    "                exposure = exposure.split('min')[0]\n",
    "            log_t_value = np.log10(float(exposure) * 60)\n",
    "        log_t.append(log_t_value)\n",
    "\n",
    "        seq = row['sequence']\n",
    "        if seq[0] == 'P':\n",
    "            max_uptake_value = len(seq) - seq.count('P')\n",
    "        else:\n",
    "            max_uptake_value = len(seq) - seq.count('P') - 1\n",
    "        max_uptake.append(max_uptake_value)\n",
    "\n",
    "        if check:\n",
    "            uptake = row['uptake']\n",
    "            percentage_d.append(uptake / float(max_uptake_value) * 100)\n",
    "\n",
    "    # Add new columns to DataFrame\n",
    "    apo_df['log_t'] = log_t\n",
    "    apo_df['max_uptake'] = max_uptake\n",
    "    if check:\n",
    "        apo_df['%d'] = percentage_d\n",
    "    return apo_df\n",
    "\n",
    "def protein_merge(start, end, sequence):\n",
    "    \n",
    "    def protein_finder(merged_protein, start, end, sequence, position): #recursive function\n",
    "        #if end[position] > start[len(start)-1]: #this deals with the end of the sequence\n",
    "        #    return merged_protein\n",
    "\n",
    "        for i in range(position, len(start)):\n",
    "            if start[i] - end[position] > 0 and start[i] - end[position] <= 10:\n",
    "                merged_protein += sequence[i]\n",
    "                return protein_finder(merged_protein, start, end, sequence, i)\n",
    "            elif start[i] - end[position] > 5:\n",
    "                break\n",
    "        return merged_protein\n",
    "    \n",
    "    position = 0 #position is the current position of the list\n",
    "    for i in range(len(start)): #it iterates down the start list, and breaks the for loop once a positive start value is reached\n",
    "        if start[i] > 0:\n",
    "            position = i\n",
    "            break\n",
    "        \n",
    "    merged_protein = sequence[position]#then it takes the first protein at the position\n",
    "    return protein_finder(merged_protein, start, end, sequence, position)\n",
    "\n",
    "collected_apo = []\n",
    "collected_mutation = []\n",
    "\n",
    "manager = open(f'{root_dir}/manager.txt', 'r')\n",
    "manager.readline() # Skip the first line\n",
    "for line in manager:\n",
    "    parts = line.strip().split(':')\n",
    "    folder_name = parts[0]\n",
    "    time_scale = parts[1]\n",
    "    print(folder_name)\n",
    "\n",
    "    file_path = os.path.join(root_dir, folder_name)\n",
    "    for file_name in ['apo_revised.xlsx', 'mutation_revised.xlsx']:\n",
    "        full_path = os.path.join(file_path, file_name)\n",
    "        if os.path.exists(full_path):\n",
    "            df = pd.read_excel(full_path)\n",
    "            if df.shape[0] == 0:\n",
    "                continue\n",
    "            if 'uptake' in df.columns and df.shape[0] > 0:\n",
    "                modified_df = modify(df, time_scale)\n",
    "                modified_df.dropna(subset=['start', 'end'], inplace=True)\n",
    "                modified_df.fillna('nan', inplace=True)\n",
    "                filename = file_name.split('.')[0] + '_modified.xlsx'\n",
    "                modified_df.to_excel(f'{file_path}/{filename}', index=False)\n",
    "\n",
    "            #df.dropna(subset=['start', 'end'], inplace=True)\n",
    "            #df.fillna('nan', inplace=True)\n",
    "\n",
    "\n",
    "            '''\n",
    "            grouped = df.groupby(['state', 'protein'], as_index=False)\n",
    "\n",
    "            for name, group in grouped:\n",
    "                group = group.drop_duplicates(subset=['sequence'])\n",
    "                group = group.sort_values('start')\n",
    "                print(name, group.shape)\n",
    "\n",
    "                start_list = group['start'].astype(int).tolist()\n",
    "                end_list = group['end'].astype(int).tolist()\n",
    "                sequence_list = group['sequence'].astype(str).tolist()\n",
    "\n",
    "                merged_protein = protein_merge(start_list, end_list, sequence_list)\n",
    "                merged_protein = merged_protein.replace(' ', '')\n",
    "                print(len(merged_protein))\n",
    "\n",
    "                if file_name == 'apo_revised.xlsx':\n",
    "                    collected_apo.append({\n",
    "                        'database_id': folder_name,\n",
    "                        'protein': name[1],\n",
    "                        'state': name[0],\n",
    "                        'merged_sequence': merged_protein\n",
    "                    })\n",
    "                elif file_name == 'mutation_revised.xlsx':\n",
    "                    collected_mutation.append({\n",
    "                        'database_id': folder_name,\n",
    "                        'protein': name[1],\n",
    "                        'state': name[0],\n",
    "                        'merged_sequence': merged_protein\n",
    "                    })\n",
    "                '''\n",
    "\n",
    "#final_apo = pd.DataFrame(collected_apo)\n",
    "#final_mutation = pd.DataFrame(collected_mutation)\n",
    "#final_apo.to_excel(f'{root_dir}/merged_apo.xlsx', index=False)\n",
    "#final_mutation.to_excel(f'{root_dir}/merged_mutation.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 18)\n",
      "(36, 18)\n",
      "25850\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "\n",
    "df = pd.read_excel(f'{root_dir}/merged_apo.xlsx', sheet_name='Sheet1')\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates(subset=['database_id'])\n",
    "print(df.shape)\n",
    "count = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    protein = row['protein']\n",
    "    state = row['state']\n",
    "    folder = row['database_id']\n",
    "    filepath = os.path.join(root_dir, folder, 'apo_revised_modified.xlsx')\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        apo_df =pd.read_excel(filepath)\n",
    "        apo_df = apo_df.drop_duplicates(subset=['sequence', 'log_t'])\n",
    "        count += apo_df.shape[0]\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liyao_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
