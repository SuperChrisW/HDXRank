{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyao/miniconda3/envs/liyao_env/lib/python3.11/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seq_embedding(merge_seq, uni_seq):\n",
    "    alignments = pairwise2.align.globalxx(merge_seq, uni_seq)\n",
    "    #print(pairwise2.format_alignment(*alignments[0]))\n",
    "    return alignments[0]\n",
    "\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmerge_seq = datafile['merged_sequence'].tolist()\\nuni_seq = datafile['uni_sequence'].tolist()\\ndatabase_id = datafile['database_id'].tolist()\\nuni_id = datafile['match_uni'].tolist()\\nstate = datafile['state'].tolist()\\n\\nscore_list = []\\nfor idx in range(len(merge_seq)):\\n    print(database_id[idx], state[idx], uni_id[idx])\\n    query_seq = merge_seq[idx].replace('-', '')\\n    alignment = seq_embedding(merge_seq[idx], uni_seq[idx])\\n    print(pairwise2.format_alignment(*alignment))\\n    score_list.append(alignment[2])\\n\\ndatafile['align_score'] = score_list\\n#datafile.to_excel(root_dir + '/merged_apo.xlsx', index=False)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/HDX_MS_dataset/database_collection'\n",
    "summary_file = root_dir + '/merged_apo.xlsx'\n",
    "datafile = pd.read_excel(summary_file)\n",
    "datafile.columns = datafile.columns.str.lower()\n",
    "datafile = datafile.drop_duplicates(subset=['match_uni'], keep='first')\n",
    "print(datafile.shape)\n",
    "\n",
    "uni_id = datafile['match_uni'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "merge_seq = datafile['merged_sequence'].tolist()\n",
    "uni_seq = datafile['uni_sequence'].tolist()\n",
    "database_id = datafile['database_id'].tolist()\n",
    "uni_id = datafile['match_uni'].tolist()\n",
    "state = datafile['state'].tolist()\n",
    "\n",
    "score_list = []\n",
    "for idx in range(len(merge_seq)):\n",
    "    print(database_id[idx], state[idx], uni_id[idx])\n",
    "    query_seq = merge_seq[idx].replace('-', '')\n",
    "    alignment = seq_embedding(merge_seq[idx], uni_seq[idx])\n",
    "    print(pairwise2.format_alignment(*alignment))\n",
    "    score_list.append(alignment[2])\n",
    "\n",
    "datafile['align_score'] = score_list\n",
    "#datafile.to_excel(root_dir + '/merged_apo.xlsx', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 14 PDSVSIPITCCFN AGGRGAPGRGRDE\n",
      "17 27 NRKIPIQRLES ESYPQRQDHEL\n",
      "18 25 RKIPIQRL SYPQRQDH\n",
      "20 39 IPIQRLESYTRITNIQCPKE PQRQDHELQALEAIYGADFQ\n",
      "32 57 TNIQCPKEAVIFKTKRGKEVCADPKE AIYGADFQDLRPDACGPVKEPPEINL\n",
      "53 76 ADPKERWVRDSMKHLDQIFQNLKP PEINLVLYPQGLTGEEVYVKVDLR\n",
      "58 71 RWVRDSMKHLDQIF VLYPQGLTGEEVYV\n",
      "58 72 RWVRDSMKHLDQIFQ VLYPQGLTGEEVYVK\n",
      "58 86 RWVRDSMKHLDQIFQNLKPSSKGGYGLND VLYPQGLTGEEVYVKVDLRVKCPPTYPDV\n",
      "60 68 VRDSMKHLD YPQGLTGEE\n",
      "60 71 VRDSMKHLDQIF YPQGLTGEEVYV\n",
      "60 72 VRDSMKHLDQIFQ YPQGLTGEEVYVK\n",
      "60 74 VRDSMKHLDQIFQNL YPQGLTGEEVYVKVD\n",
      "60 84 VRDSMKHLDQIFQNLKPSSKGGYGL YPQGLTGEEVYVKVDLRVKCPPTYP\n",
      "60 86 VRDSMKHLDQIFQNLKPSSKGGYGLND YPQGLTGEEVYVKVDLRVKCPPTYPDV\n",
      "60 88 VRDSMKHLDQIFQNLKPSSKGGYGLNDIF YPQGLTGEEVYVKVDLRVKCPPTYPDVVP\n",
      "63 71 SMKHLDQIF GLTGEEVYV\n",
      "63 72 SMKHLDQIFQ GLTGEEVYVK\n",
      "63 74 SMKHLDQIFQNL GLTGEEVYVKVD\n",
      "63 85 SMKHLDQIFQNLKPSSKGGYGLN GLTGEEVYVKVDLRVKCPPTYPD\n",
      "63 86 SMKHLDQIFQNLKPSSKGGYGLND GLTGEEVYVKVDLRVKCPPTYPDV\n",
      "63 87 SMKHLDQIFQNLKPSSKGGYGLNDI GLTGEEVYVKVDLRVKCPPTYPDVV\n",
      "63 88 SMKHLDQIFQNLKPSSKGGYGLNDIF GLTGEEVYVKVDLRVKCPPTYPDVVP\n",
      "63 89 SMKHLDQIFQNLKPSSKGGYGLNDIFE GLTGEEVYVKVDLRVKCPPTYPDVVPE\n",
      "65 86 KHLDQIFQNLKPSSKGGYGLND TGEEVYVKVDLRVKCPPTYPDV\n",
      "65 88 KHLDQIFQNLKPSSKGGYGLNDIF TGEEVYVKVDLRVKCPPTYPDVVP\n",
      "68 85 DQIFQNLKPSSKGGYGLN EVYVKVDLRVKCPPTYPD\n",
      "68 86 DQIFQNLKPSSKGGYGLND EVYVKVDLRVKCPPTYPDV\n",
      "68 88 DQIFQNLKPSSKGGYGLNDIF EVYVKVDLRVKCPPTYPDVVP\n",
      "70 85 IFQNLKPSSKGGYGLN YVKVDLRVKCPPTYPD\n",
      "70 88 IFQNLKPSSKGGYGLNDIF YVKVDLRVKCPPTYPDVVP\n",
      "71 88 FQNLKPSSKGGYGLNDIF VKVDLRVKCPPTYPDVVP\n",
      "72 86 QNLKPSSKGGYGLND KVDLRVKCPPTYPDV\n",
      "72 88 QNLKPSSKGGYGLNDIF KVDLRVKCPPTYPDVVP\n",
      "72 89 QNLKPSSKGGYGLNDIFE KVDLRVKCPPTYPDVVPE\n",
      "73 85 NLKPSSKGGYGLN VDLRVKCPPTYPD\n",
      "73 86 NLKPSSKGGYGLND VDLRVKCPPTYPDV\n",
      "73 88 NLKPSSKGGYGLNDIF VDLRVKCPPTYPDVVP\n",
      "75 88 KPSSKGGYGLNDIF LRVKCPPTYPDVVP\n",
      "87 97 IFEAQKIEWHE VPEIELKNAKG\n",
      "89 97 EAQKIEWHE EIELKNAKG\n",
      "90 97 AQKIEWHE IELKNAKG\n",
      "91 97 QKIEWHE ELKNAKG\n",
      "91 97 QKIEWHE ELKNAKG\n"
     ]
    }
   ],
   "source": [
    "id = idx-1\n",
    "fname = 'CCL8'\n",
    "csv_df = pd.read_csv(f'/Users/liyao/Desktop/Tsuda_Lab/Source_code/AI-HDX-main/dataset/filtered_results/{fname}_filtered.csv')\n",
    "\n",
    "csv_seq = csv_df['Sequence'].tolist()\n",
    "csv_start = csv_df['Start'].tolist()\n",
    "csv_end = csv_df['End'].tolist()\n",
    "whole_seq = uni_seq[id]\n",
    "\n",
    "for index, (start_id, end_id, seq) in enumerate(zip(csv_start, csv_end, csv_seq)):\n",
    "    if not seq == whole_seq[start_id - 1: end_id]:\n",
    "        print(start_id, end_id, seq, whole_seq[start_id - 1: end_id])\n",
    "#        seq_embedding(seq, whole_seq)\n",
    "#        break\n",
    "    pass\n",
    "#seq_embedding(merge_seq[id], uni_seq[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S5FWF8\n",
      "P59768\n",
      "P00734\n",
      "P62873\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = '/Users/liyao/Desktop/Tsuda_Lab/Source_code/PDBminer/results'\n",
    "folder_list = os.listdir(root_dir)\n",
    "\n",
    "for folder in folder_list:\n",
    "    filename = f'{folder}_all.json'\n",
    "    filepath = os.path.join(root_dir, folder, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        if folder in uni_id:\n",
    "            print(folder)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liyao_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
